{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import MNISTLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_size=20\n",
    "feature_size=784\n",
    "output_size=10\n",
    "epochs=500\n",
    "alpha=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A=np.arrange(20).reshape(5,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "tf.set_random_seed(100)\n",
    "w0=tf.Variable(np.random.randn(hidden_size,feature_size),dtype=tf.float32)\n",
    "w1=tf.Variable(np.random.randn(output_size,hidden_size),dtype=tf.float32)\n",
    "b0=tf.Variable(np.zeros((hidden_size,1)),dtype=tf.float32)\n",
    "b1=tf.Variable(np.zeros((output_size,1)),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=tf.placeholder(tf.float32)\n",
    "y=tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a0=tf.sigmoid(tf.matmul(w0,x)+b0)\n",
    "a1=tf.sigmoid(tf.matmul(w1,a0)+b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data,valid_data,test_data=MNISTLoader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CALCULATE COST\n",
    "cost=tf.reduce_sum(tf.reduce_mean((a1-y)**2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer=tf.train.GradientDescentOptimizer(alpha)\n",
    "training=optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 : loss = 4.30095\n",
      "Epoch  1 : loss = 2.94144\n",
      "Epoch  2 : loss = 1.86845\n",
      "Epoch  3 : loss = 1.35166\n",
      "Epoch  4 : loss = 1.15373\n",
      "Epoch  5 : loss = 1.06992\n",
      "Epoch  6 : loss = 1.02679\n",
      "Epoch  7 : loss = 1.00118\n",
      "Epoch  8 : loss = 0.984389\n",
      "Epoch  9 : loss = 0.972547\n",
      "Epoch  10 : loss = 0.963705\n",
      "Epoch  11 : loss = 0.956793\n",
      "Epoch  12 : loss = 0.95118\n",
      "Epoch  13 : loss = 0.946471\n",
      "Epoch  14 : loss = 0.942411\n",
      "Epoch  15 : loss = 0.938829\n",
      "Epoch  16 : loss = 0.935605\n",
      "Epoch  17 : loss = 0.932657\n",
      "Epoch  18 : loss = 0.929923\n",
      "Epoch  19 : loss = 0.927361\n",
      "Epoch  20 : loss = 0.924937\n",
      "Epoch  21 : loss = 0.922626\n",
      "Epoch  22 : loss = 0.920411\n",
      "Epoch  23 : loss = 0.918279\n",
      "Epoch  24 : loss = 0.916217\n",
      "Epoch  25 : loss = 0.914218\n",
      "Epoch  26 : loss = 0.912275\n",
      "Epoch  27 : loss = 0.910382\n",
      "Epoch  28 : loss = 0.908535\n",
      "Epoch  29 : loss = 0.90673\n",
      "Epoch  30 : loss = 0.904965\n",
      "Epoch  31 : loss = 0.903235\n",
      "Epoch  32 : loss = 0.90154\n",
      "Epoch  33 : loss = 0.899876\n",
      "Epoch  34 : loss = 0.898242\n",
      "Epoch  35 : loss = 0.896636\n",
      "Epoch  36 : loss = 0.895058\n",
      "Epoch  37 : loss = 0.893503\n",
      "Epoch  38 : loss = 0.891974\n",
      "Epoch  39 : loss = 0.890466\n",
      "Epoch  40 : loss = 0.888981\n",
      "Epoch  41 : loss = 0.887516\n",
      "Epoch  42 : loss = 0.886072\n",
      "Epoch  43 : loss = 0.884646\n",
      "Epoch  44 : loss = 0.883238\n",
      "Epoch  45 : loss = 0.881847\n",
      "Epoch  46 : loss = 0.880473\n",
      "Epoch  47 : loss = 0.879116\n",
      "Epoch  48 : loss = 0.877773\n",
      "Epoch  49 : loss = 0.876446\n",
      "Epoch  50 : loss = 0.875133\n",
      "Epoch  51 : loss = 0.873833\n",
      "Epoch  52 : loss = 0.872547\n",
      "Epoch  53 : loss = 0.871273\n",
      "Epoch  54 : loss = 0.870012\n",
      "Epoch  55 : loss = 0.868762\n",
      "Epoch  56 : loss = 0.867524\n",
      "Epoch  57 : loss = 0.866296\n",
      "Epoch  58 : loss = 0.86508\n",
      "Epoch  59 : loss = 0.863873\n",
      "Epoch  60 : loss = 0.862676\n",
      "Epoch  61 : loss = 0.861489\n",
      "Epoch  62 : loss = 0.860312\n",
      "Epoch  63 : loss = 0.859143\n",
      "Epoch  64 : loss = 0.857982\n",
      "Epoch  65 : loss = 0.85683\n",
      "Epoch  66 : loss = 0.855686\n",
      "Epoch  67 : loss = 0.854549\n",
      "Epoch  68 : loss = 0.85342\n",
      "Epoch  69 : loss = 0.852298\n",
      "Epoch  70 : loss = 0.851182\n",
      "Epoch  71 : loss = 0.850074\n",
      "Epoch  72 : loss = 0.848971\n",
      "Epoch  73 : loss = 0.847875\n",
      "Epoch  74 : loss = 0.846784\n",
      "Epoch  75 : loss = 0.845699\n",
      "Epoch  76 : loss = 0.84462\n",
      "Epoch  77 : loss = 0.843545\n",
      "Epoch  78 : loss = 0.842476\n",
      "Epoch  79 : loss = 0.841411\n",
      "Epoch  80 : loss = 0.84035\n",
      "Epoch  81 : loss = 0.839294\n",
      "Epoch  82 : loss = 0.838243\n",
      "Epoch  83 : loss = 0.837196\n",
      "Epoch  84 : loss = 0.836152\n",
      "Epoch  85 : loss = 0.835113\n",
      "Epoch  86 : loss = 0.834077\n",
      "Epoch  87 : loss = 0.833045\n",
      "Epoch  88 : loss = 0.832017\n",
      "Epoch  89 : loss = 0.830992\n",
      "Epoch  90 : loss = 0.82997\n",
      "Epoch  91 : loss = 0.828952\n",
      "Epoch  92 : loss = 0.827938\n",
      "Epoch  93 : loss = 0.826926\n",
      "Epoch  94 : loss = 0.825919\n",
      "Epoch  95 : loss = 0.824913\n",
      "Epoch  96 : loss = 0.823912\n",
      "Epoch  97 : loss = 0.822913\n",
      "Epoch  98 : loss = 0.821918\n",
      "Epoch  99 : loss = 0.820925\n",
      "Epoch  100 : loss = 0.819936\n",
      "Epoch  101 : loss = 0.81895\n",
      "Epoch  102 : loss = 0.817967\n",
      "Epoch  103 : loss = 0.816987\n",
      "Epoch  104 : loss = 0.81601\n",
      "Epoch  105 : loss = 0.815037\n",
      "Epoch  106 : loss = 0.814066\n",
      "Epoch  107 : loss = 0.813098\n",
      "Epoch  108 : loss = 0.812133\n",
      "Epoch  109 : loss = 0.811171\n",
      "Epoch  110 : loss = 0.810213\n",
      "Epoch  111 : loss = 0.809257\n",
      "Epoch  112 : loss = 0.808304\n",
      "Epoch  113 : loss = 0.807354\n",
      "Epoch  114 : loss = 0.806407\n",
      "Epoch  115 : loss = 0.805463\n",
      "Epoch  116 : loss = 0.804521\n",
      "Epoch  117 : loss = 0.803583\n",
      "Epoch  118 : loss = 0.802647\n",
      "Epoch  119 : loss = 0.801713\n",
      "Epoch  120 : loss = 0.800784\n",
      "Epoch  121 : loss = 0.799856\n",
      "Epoch  122 : loss = 0.798931\n",
      "Epoch  123 : loss = 0.798009\n",
      "Epoch  124 : loss = 0.79709\n",
      "Epoch  125 : loss = 0.796174\n",
      "Epoch  126 : loss = 0.795259\n",
      "Epoch  127 : loss = 0.794348\n",
      "Epoch  128 : loss = 0.793439\n",
      "Epoch  129 : loss = 0.792534\n",
      "Epoch  130 : loss = 0.79163\n",
      "Epoch  131 : loss = 0.79073\n",
      "Epoch  132 : loss = 0.789832\n",
      "Epoch  133 : loss = 0.788937\n",
      "Epoch  134 : loss = 0.788045\n",
      "Epoch  135 : loss = 0.787155\n",
      "Epoch  136 : loss = 0.786268\n",
      "Epoch  137 : loss = 0.785383\n",
      "Epoch  138 : loss = 0.784502\n",
      "Epoch  139 : loss = 0.783622\n",
      "Epoch  140 : loss = 0.782745\n",
      "Epoch  141 : loss = 0.78187\n",
      "Epoch  142 : loss = 0.780998\n",
      "Epoch  143 : loss = 0.780128\n",
      "Epoch  144 : loss = 0.77926\n",
      "Epoch  145 : loss = 0.778394\n",
      "Epoch  146 : loss = 0.777531\n",
      "Epoch  147 : loss = 0.776669\n",
      "Epoch  148 : loss = 0.775809\n",
      "Epoch  149 : loss = 0.774951\n",
      "Epoch  150 : loss = 0.774094\n",
      "Epoch  151 : loss = 0.773239\n",
      "Epoch  152 : loss = 0.772385\n",
      "Epoch  153 : loss = 0.771533\n",
      "Epoch  154 : loss = 0.770682\n",
      "Epoch  155 : loss = 0.769832\n",
      "Epoch  156 : loss = 0.768983\n",
      "Epoch  157 : loss = 0.768135\n",
      "Epoch  158 : loss = 0.767289\n",
      "Epoch  159 : loss = 0.766442\n",
      "Epoch  160 : loss = 0.765597\n",
      "Epoch  161 : loss = 0.764752\n",
      "Epoch  162 : loss = 0.763908\n",
      "Epoch  163 : loss = 0.763064\n",
      "Epoch  164 : loss = 0.762221\n",
      "Epoch  165 : loss = 0.761378\n",
      "Epoch  166 : loss = 0.760536\n",
      "Epoch  167 : loss = 0.759695\n",
      "Epoch  168 : loss = 0.758853\n",
      "Epoch  169 : loss = 0.758013\n",
      "Epoch  170 : loss = 0.757172\n",
      "Epoch  171 : loss = 0.756333\n",
      "Epoch  172 : loss = 0.755493\n",
      "Epoch  173 : loss = 0.754655\n",
      "Epoch  174 : loss = 0.753816\n",
      "Epoch  175 : loss = 0.752978\n",
      "Epoch  176 : loss = 0.752141\n",
      "Epoch  177 : loss = 0.751304\n",
      "Epoch  178 : loss = 0.750467\n",
      "Epoch  179 : loss = 0.749632\n",
      "Epoch  180 : loss = 0.748796\n",
      "Epoch  181 : loss = 0.747961\n",
      "Epoch  182 : loss = 0.747127\n",
      "Epoch  183 : loss = 0.746293\n",
      "Epoch  184 : loss = 0.74546\n",
      "Epoch  185 : loss = 0.744627\n",
      "Epoch  186 : loss = 0.743795\n",
      "Epoch  187 : loss = 0.742964\n",
      "Epoch  188 : loss = 0.742133\n",
      "Epoch  189 : loss = 0.741302\n",
      "Epoch  190 : loss = 0.740473\n",
      "Epoch  191 : loss = 0.739643\n",
      "Epoch  192 : loss = 0.738815\n",
      "Epoch  193 : loss = 0.737986\n",
      "Epoch  194 : loss = 0.737158\n",
      "Epoch  195 : loss = 0.73633\n",
      "Epoch  196 : loss = 0.735503\n",
      "Epoch  197 : loss = 0.734676\n",
      "Epoch  198 : loss = 0.733849\n",
      "Epoch  199 : loss = 0.733023\n",
      "Epoch  200 : loss = 0.732197\n",
      "Epoch  201 : loss = 0.731371\n",
      "Epoch  202 : loss = 0.730545\n",
      "Epoch  203 : loss = 0.72972\n",
      "Epoch  204 : loss = 0.728894\n",
      "Epoch  205 : loss = 0.728069\n",
      "Epoch  206 : loss = 0.727243\n",
      "Epoch  207 : loss = 0.726418\n",
      "Epoch  208 : loss = 0.725592\n",
      "Epoch  209 : loss = 0.724767\n",
      "Epoch  210 : loss = 0.723942\n",
      "Epoch  211 : loss = 0.723116\n",
      "Epoch  212 : loss = 0.722291\n",
      "Epoch  213 : loss = 0.721466\n",
      "Epoch  214 : loss = 0.72064\n",
      "Epoch  215 : loss = 0.719815\n",
      "Epoch  216 : loss = 0.718989\n",
      "Epoch  217 : loss = 0.718164\n",
      "Epoch  218 : loss = 0.717339\n",
      "Epoch  219 : loss = 0.716513\n",
      "Epoch  220 : loss = 0.715688\n",
      "Epoch  221 : loss = 0.714862\n",
      "Epoch  222 : loss = 0.714037\n",
      "Epoch  223 : loss = 0.713211\n",
      "Epoch  224 : loss = 0.712386\n",
      "Epoch  225 : loss = 0.71156\n",
      "Epoch  226 : loss = 0.710734\n",
      "Epoch  227 : loss = 0.709908\n",
      "Epoch  228 : loss = 0.709082\n",
      "Epoch  229 : loss = 0.708255\n",
      "Epoch  230 : loss = 0.707429\n",
      "Epoch  231 : loss = 0.706602\n",
      "Epoch  232 : loss = 0.705775\n",
      "Epoch  233 : loss = 0.704949\n",
      "Epoch  234 : loss = 0.704121\n",
      "Epoch  235 : loss = 0.703294\n",
      "Epoch  236 : loss = 0.702466\n",
      "Epoch  237 : loss = 0.701638\n",
      "Epoch  238 : loss = 0.70081\n",
      "Epoch  239 : loss = 0.699983\n",
      "Epoch  240 : loss = 0.699154\n",
      "Epoch  241 : loss = 0.698325\n",
      "Epoch  242 : loss = 0.697497\n",
      "Epoch  243 : loss = 0.696668\n",
      "Epoch  244 : loss = 0.695839\n",
      "Epoch  245 : loss = 0.69501\n",
      "Epoch  246 : loss = 0.694181\n",
      "Epoch  247 : loss = 0.693352\n",
      "Epoch  248 : loss = 0.692524\n",
      "Epoch  249 : loss = 0.691694\n",
      "Epoch  250 : loss = 0.690865\n",
      "Epoch  251 : loss = 0.690036\n",
      "Epoch  252 : loss = 0.689208\n",
      "Epoch  253 : loss = 0.688379\n",
      "Epoch  254 : loss = 0.687551\n",
      "Epoch  255 : loss = 0.686723\n",
      "Epoch  256 : loss = 0.685895\n",
      "Epoch  257 : loss = 0.685067\n",
      "Epoch  258 : loss = 0.684241\n",
      "Epoch  259 : loss = 0.683414\n",
      "Epoch  260 : loss = 0.682588\n",
      "Epoch  261 : loss = 0.681762\n",
      "Epoch  262 : loss = 0.680937\n",
      "Epoch  263 : loss = 0.680112\n",
      "Epoch  264 : loss = 0.679289\n",
      "Epoch  265 : loss = 0.678465\n",
      "Epoch  266 : loss = 0.677642\n",
      "Epoch  267 : loss = 0.67682\n",
      "Epoch  268 : loss = 0.675999\n",
      "Epoch  269 : loss = 0.675179\n",
      "Epoch  270 : loss = 0.674359\n",
      "Epoch  271 : loss = 0.67354\n",
      "Epoch  272 : loss = 0.672723\n",
      "Epoch  273 : loss = 0.671906\n",
      "Epoch  274 : loss = 0.671091\n",
      "Epoch  275 : loss = 0.670277\n",
      "Epoch  276 : loss = 0.669464\n",
      "Epoch  277 : loss = 0.668652\n",
      "Epoch  278 : loss = 0.667841\n",
      "Epoch  279 : loss = 0.667031\n",
      "Epoch  280 : loss = 0.666223\n",
      "Epoch  281 : loss = 0.665417\n",
      "Epoch  282 : loss = 0.664612\n",
      "Epoch  283 : loss = 0.663808\n",
      "Epoch  284 : loss = 0.663007\n",
      "Epoch  285 : loss = 0.662206\n",
      "Epoch  286 : loss = 0.661408\n",
      "Epoch  287 : loss = 0.660611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  288 : loss = 0.659816\n",
      "Epoch  289 : loss = 0.659023\n",
      "Epoch  290 : loss = 0.658231\n",
      "Epoch  291 : loss = 0.657442\n",
      "Epoch  292 : loss = 0.656655\n",
      "Epoch  293 : loss = 0.65587\n",
      "Epoch  294 : loss = 0.655087\n",
      "Epoch  295 : loss = 0.654306\n",
      "Epoch  296 : loss = 0.653527\n",
      "Epoch  297 : loss = 0.652751\n",
      "Epoch  298 : loss = 0.651976\n",
      "Epoch  299 : loss = 0.651204\n",
      "Epoch  300 : loss = 0.650434\n",
      "Epoch  301 : loss = 0.649667\n",
      "Epoch  302 : loss = 0.648902\n",
      "Epoch  303 : loss = 0.648139\n",
      "Epoch  304 : loss = 0.647379\n",
      "Epoch  305 : loss = 0.646621\n",
      "Epoch  306 : loss = 0.645866\n",
      "Epoch  307 : loss = 0.645113\n",
      "Epoch  308 : loss = 0.644363\n",
      "Epoch  309 : loss = 0.643615\n",
      "Epoch  310 : loss = 0.64287\n",
      "Epoch  311 : loss = 0.642127\n",
      "Epoch  312 : loss = 0.641387\n",
      "Epoch  313 : loss = 0.640649\n",
      "Epoch  314 : loss = 0.639914\n",
      "Epoch  315 : loss = 0.639182\n",
      "Epoch  316 : loss = 0.638451\n",
      "Epoch  317 : loss = 0.637724\n",
      "Epoch  318 : loss = 0.637\n",
      "Epoch  319 : loss = 0.636278\n",
      "Epoch  320 : loss = 0.635558\n",
      "Epoch  321 : loss = 0.634842\n",
      "Epoch  322 : loss = 0.634127\n",
      "Epoch  323 : loss = 0.633416\n",
      "Epoch  324 : loss = 0.632707\n",
      "Epoch  325 : loss = 0.632001\n",
      "Epoch  326 : loss = 0.631298\n",
      "Epoch  327 : loss = 0.630597\n",
      "Epoch  328 : loss = 0.629899\n",
      "Epoch  329 : loss = 0.629204\n",
      "Epoch  330 : loss = 0.628511\n",
      "Epoch  331 : loss = 0.627821\n",
      "Epoch  332 : loss = 0.627134\n",
      "Epoch  333 : loss = 0.626449\n",
      "Epoch  334 : loss = 0.625767\n",
      "Epoch  335 : loss = 0.625088\n",
      "Epoch  336 : loss = 0.624411\n",
      "Epoch  337 : loss = 0.623738\n",
      "Epoch  338 : loss = 0.623067\n",
      "Epoch  339 : loss = 0.622398\n",
      "Epoch  340 : loss = 0.621732\n",
      "Epoch  341 : loss = 0.62107\n",
      "Epoch  342 : loss = 0.620409\n",
      "Epoch  343 : loss = 0.619752\n",
      "Epoch  344 : loss = 0.619097\n",
      "Epoch  345 : loss = 0.618445\n",
      "Epoch  346 : loss = 0.617796\n",
      "Epoch  347 : loss = 0.617149\n",
      "Epoch  348 : loss = 0.616505\n",
      "Epoch  349 : loss = 0.615864\n",
      "Epoch  350 : loss = 0.615226\n",
      "Epoch  351 : loss = 0.61459\n",
      "Epoch  352 : loss = 0.613956\n",
      "Epoch  353 : loss = 0.613326\n",
      "Epoch  354 : loss = 0.612698\n",
      "Epoch  355 : loss = 0.612073\n",
      "Epoch  356 : loss = 0.61145\n",
      "Epoch  357 : loss = 0.61083\n",
      "Epoch  358 : loss = 0.610213\n",
      "Epoch  359 : loss = 0.609599\n",
      "Epoch  360 : loss = 0.608986\n",
      "Epoch  361 : loss = 0.608377\n",
      "Epoch  362 : loss = 0.60777\n",
      "Epoch  363 : loss = 0.607166\n",
      "Epoch  364 : loss = 0.606564\n",
      "Epoch  365 : loss = 0.605965\n",
      "Epoch  366 : loss = 0.605369\n",
      "Epoch  367 : loss = 0.604775\n",
      "Epoch  368 : loss = 0.604184\n",
      "Epoch  369 : loss = 0.603595\n",
      "Epoch  370 : loss = 0.603009\n",
      "Epoch  371 : loss = 0.602425\n",
      "Epoch  372 : loss = 0.601843\n",
      "Epoch  373 : loss = 0.601264\n",
      "Epoch  374 : loss = 0.600688\n",
      "Epoch  375 : loss = 0.600114\n",
      "Epoch  376 : loss = 0.599542\n",
      "Epoch  377 : loss = 0.598973\n",
      "Epoch  378 : loss = 0.598407\n",
      "Epoch  379 : loss = 0.597842\n",
      "Epoch  380 : loss = 0.59728\n",
      "Epoch  381 : loss = 0.596721\n",
      "Epoch  382 : loss = 0.596164\n",
      "Epoch  383 : loss = 0.595609\n",
      "Epoch  384 : loss = 0.595056\n",
      "Epoch  385 : loss = 0.594506\n",
      "Epoch  386 : loss = 0.593958\n",
      "Epoch  387 : loss = 0.593413\n",
      "Epoch  388 : loss = 0.592869\n",
      "Epoch  389 : loss = 0.592328\n",
      "Epoch  390 : loss = 0.59179\n",
      "Epoch  391 : loss = 0.591253\n",
      "Epoch  392 : loss = 0.590719\n",
      "Epoch  393 : loss = 0.590187\n",
      "Epoch  394 : loss = 0.589657\n",
      "Epoch  395 : loss = 0.589129\n",
      "Epoch  396 : loss = 0.588604\n",
      "Epoch  397 : loss = 0.588081\n",
      "Epoch  398 : loss = 0.587559\n",
      "Epoch  399 : loss = 0.58704\n",
      "Epoch  400 : loss = 0.586523\n",
      "Epoch  401 : loss = 0.586008\n",
      "Epoch  402 : loss = 0.585495\n",
      "Epoch  403 : loss = 0.584985\n",
      "Epoch  404 : loss = 0.584476\n",
      "Epoch  405 : loss = 0.583969\n",
      "Epoch  406 : loss = 0.583465\n",
      "Epoch  407 : loss = 0.582962\n",
      "Epoch  408 : loss = 0.582462\n",
      "Epoch  409 : loss = 0.581964\n",
      "Epoch  410 : loss = 0.581467\n",
      "Epoch  411 : loss = 0.580973\n",
      "Epoch  412 : loss = 0.58048\n",
      "Epoch  413 : loss = 0.57999\n",
      "Epoch  414 : loss = 0.579501\n",
      "Epoch  415 : loss = 0.579014\n",
      "Epoch  416 : loss = 0.578529\n",
      "Epoch  417 : loss = 0.578047\n",
      "Epoch  418 : loss = 0.577566\n",
      "Epoch  419 : loss = 0.577087\n",
      "Epoch  420 : loss = 0.576609\n",
      "Epoch  421 : loss = 0.576134\n",
      "Epoch  422 : loss = 0.575661\n",
      "Epoch  423 : loss = 0.575188\n",
      "Epoch  424 : loss = 0.574718\n",
      "Epoch  425 : loss = 0.57425\n",
      "Epoch  426 : loss = 0.573784\n",
      "Epoch  427 : loss = 0.573319\n",
      "Epoch  428 : loss = 0.572857\n",
      "Epoch  429 : loss = 0.572396\n",
      "Epoch  430 : loss = 0.571936\n",
      "Epoch  431 : loss = 0.571478\n",
      "Epoch  432 : loss = 0.571023\n",
      "Epoch  433 : loss = 0.570568\n",
      "Epoch  434 : loss = 0.570116\n",
      "Epoch  435 : loss = 0.569665\n",
      "Epoch  436 : loss = 0.569216\n",
      "Epoch  437 : loss = 0.568768\n",
      "Epoch  438 : loss = 0.568322\n",
      "Epoch  439 : loss = 0.567878\n",
      "Epoch  440 : loss = 0.567435\n",
      "Epoch  441 : loss = 0.566994\n",
      "Epoch  442 : loss = 0.566554\n",
      "Epoch  443 : loss = 0.566117\n",
      "Epoch  444 : loss = 0.56568\n",
      "Epoch  445 : loss = 0.565245\n",
      "Epoch  446 : loss = 0.564812\n",
      "Epoch  447 : loss = 0.56438\n",
      "Epoch  448 : loss = 0.56395\n",
      "Epoch  449 : loss = 0.563521\n",
      "Epoch  450 : loss = 0.563094\n",
      "Epoch  451 : loss = 0.562668\n",
      "Epoch  452 : loss = 0.562243\n",
      "Epoch  453 : loss = 0.56182\n",
      "Epoch  454 : loss = 0.561399\n",
      "Epoch  455 : loss = 0.560979\n",
      "Epoch  456 : loss = 0.56056\n",
      "Epoch  457 : loss = 0.560143\n",
      "Epoch  458 : loss = 0.559727\n",
      "Epoch  459 : loss = 0.559313\n",
      "Epoch  460 : loss = 0.5589\n",
      "Epoch  461 : loss = 0.558488\n",
      "Epoch  462 : loss = 0.558078\n",
      "Epoch  463 : loss = 0.557669\n",
      "Epoch  464 : loss = 0.557262\n",
      "Epoch  465 : loss = 0.556855\n",
      "Epoch  466 : loss = 0.556451\n",
      "Epoch  467 : loss = 0.556047\n",
      "Epoch  468 : loss = 0.555644\n",
      "Epoch  469 : loss = 0.555243\n",
      "Epoch  470 : loss = 0.554844\n",
      "Epoch  471 : loss = 0.554445\n",
      "Epoch  472 : loss = 0.554047\n",
      "Epoch  473 : loss = 0.553652\n",
      "Epoch  474 : loss = 0.553257\n",
      "Epoch  475 : loss = 0.552863\n",
      "Epoch  476 : loss = 0.552471\n",
      "Epoch  477 : loss = 0.55208\n",
      "Epoch  478 : loss = 0.55169\n",
      "Epoch  479 : loss = 0.551301\n",
      "Epoch  480 : loss = 0.550914\n",
      "Epoch  481 : loss = 0.550527\n",
      "Epoch  482 : loss = 0.550142\n",
      "Epoch  483 : loss = 0.549758\n",
      "Epoch  484 : loss = 0.549375\n",
      "Epoch  485 : loss = 0.548993\n",
      "Epoch  486 : loss = 0.548613\n",
      "Epoch  487 : loss = 0.548233\n",
      "Epoch  488 : loss = 0.547855\n",
      "Epoch  489 : loss = 0.547478\n",
      "Epoch  490 : loss = 0.547101\n",
      "Epoch  491 : loss = 0.546726\n",
      "Epoch  492 : loss = 0.546352\n",
      "Epoch  493 : loss = 0.545979\n",
      "Epoch  494 : loss = 0.545607\n",
      "Epoch  495 : loss = 0.545236\n",
      "Epoch  496 : loss = 0.544866\n",
      "Epoch  497 : loss = 0.544497\n",
      "Epoch  498 : loss = 0.54413\n",
      "Epoch  499 : loss = 0.543763\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        sess.run(training,feed_dict = {x:train_data[0],y:train_data[1]})\n",
    "        loss=sess.run(cost,feed_dict = {x:train_data[0],y:train_data[1]})\n",
    "        print(\"Epoch \", i, \": loss =\",loss)\n",
    "    nw0,nw1,nb0,nb1=sess.run([w0,w1,b0,b1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ng=tf.Graph()\\nwith g.as_default():\\n    xt=tf.placeholder(tf.float32)\\n    yt=tf.placeholder(tf.float32)\\n    nw0=tf.Constant(nw0)#Numpy se TensorFlow Const\\n    nw1=tf.Constant(nw1)\\n    nb0=tf.Constant(nb0)\\n    nb1=tf.Constant(nb1)\\n    \\n    na0=tf.sigmoid(tf.matmul(nw0,xt)+nb0)\\n    na1=tf.sigmoid(tf.matmul(nw1,na0)+nb1)\\n    \\n    with tf.Session() as sess:\\n        \\n       sess.run(tf.global_variables_initializer())\\n    \\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "g=tf.Graph()\n",
    "with g.as_default():\n",
    "    xt=tf.placeholder(tf.float32)\n",
    "    yt=tf.placeholder(tf.float32)\n",
    "    nw0=tf.Constant(nw0)#Numpy se TensorFlow Const\n",
    "    nw1=tf.Constant(nw1)\n",
    "    nb0=tf.Constant(nb0)\n",
    "    nb1=tf.Constant(nb1)\n",
    "    \n",
    "    na0=tf.sigmoid(tf.matmul(nw0,xt)+nb0)\n",
    "    na1=tf.sigmoid(tf.matmul(nw1,na0)+nb1)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "       sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 61.58 %\n"
     ]
    }
   ],
   "source": [
    "xt=test_data[0]\n",
    "yt=test_data[1]\n",
    "\n",
    "na0=sigmoid((np.dot(nw0,xt))+nb0)\n",
    "na1=sigmoid((np.dot(nw1,na0))+nb1)\n",
    "\n",
    "predictions=na1.argmax(axis=0)\n",
    "\n",
    "myfilter =np.equal( predictions , yt)\n",
    "accuracy=len(predictions[myfilter])/len(predictions)\n",
    "print(\"accuracy =\",accuracy*100,\"%\")\n",
    "#(\"Epoch \", i, \": "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
